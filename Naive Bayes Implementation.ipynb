{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries and functions\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required datasets\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups=fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys in the dataset\n",
    "newsgroups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=newsgroups.data\n",
    "y=newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The target values 0,1,2,3...19 correspond to the target_names in the newsgroups\n",
    "## meaning,\n",
    "## 0 indicates alt.atheism category\n",
    "## 1 indicates comp.graphics category and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and testing\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# list of stopwords taken from Internet\n",
    "\n",
    "stopwords = ['i','me','my','myself','we','our','ours','ourselves','you',\"you're\",\"you've\",\"you'll\",\"you'd\",'your','yours','yourself','yourselves','he','him','his','himself','she',\"she's\",'her','hers','herself','it',\"it's\",'its','itself','they',\n",
    " 'them','their','theirs','themselves','what','which','who','whom','this','that',\"that'll\",'these','those','am','is','are','was','were','be',\n",
    " 'been','being','have','has','had','having','do','does','did','doing','a','an','the','and',\n",
    " 'but','if','or','because','as','until','while','of','at','by','for','with','about','against','between','into','through','during',\n",
    " 'before','after','above','below',\n",
    " 'to','from','up','down','in','out','on','off','over','under','again',\n",
    " 'further','then','once','here','there','when','where','why','how','all','any','both','each',\n",
    " 'few','more','most','other','some','such','no','nor','not','only','own','same','so','than','too','very','s','t','can','will','just',\n",
    " 'don',\"don't\",'should',\"should've\",'now','d','ll','m','o','re','ve','y','ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven',\"haven't\",'isn',\"isn't\",'ma','mightn',\"mightn't\",'mustn','could','may',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "# removing the digits and punctuations\n",
    "\n",
    "def data_clean(sentence):\n",
    "    \n",
    "    # removing any digits present in the sentence\n",
    "    sentence = list(''.join([i for i in sentence if not i.isdigit()]))\n",
    "    \n",
    "    # removing all the punctuation marks in the sentence\n",
    "    p = list(sentence)\n",
    "    for j in range(len(p)):\n",
    "        if p[j] in string.punctuation:\n",
    "            p[j]=''\n",
    "            \n",
    "    # return the complete sentence after joining the words\n",
    "    return ''.join(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to account for the frequency of all words in the documents\n",
    "\n",
    "d={}\n",
    "for i in range(len(x_train)):\n",
    "    a = x_train[i].split('\\n')\n",
    "    for sentence in a:\n",
    "        clean_sentence = data_clean(sentence)\n",
    "        \n",
    "        # removing stopwords\n",
    "        for i in range(len(clean_sentence.split())):\n",
    "            word=clean_sentence.split()[i].lower()\n",
    "            if word in stopwords or len(word)<=2:\n",
    "                continue\n",
    "            \n",
    "            # creating the dictionary\n",
    "            d[word]=d.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=np.array(list(d.values()))\n",
    "keys=np.array(list(d.keys()))\n",
    "\n",
    "# sorting in descending order\n",
    "index=np.argsort(values)\n",
    "index=index[::-1]\n",
    "values=values[index]\n",
    "keys=keys[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting the top words\n",
    "# words within threshold, a particular cut-off.\n",
    "\n",
    "threshold = 5000\n",
    "features = keys[:threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the 2d array\n",
    "# vocabulary is the 2d array\n",
    "\n",
    "def get_2d_array(x,features):\n",
    "    size=len(x)*threshold\n",
    "    \n",
    "    # 2d array \n",
    "    vocabulary = np.zeros(size).reshape(len(x),threshold)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        # splitting the paragraph into sentences\n",
    "        a = x[i].split('\\n')\n",
    "        \n",
    "        # iterating over sentences\n",
    "        # and cleaning each one of them\n",
    "        for sentence in a:\n",
    "            clean_sentence = data_clean(sentence)\n",
    "            \n",
    "            for j in range(len(clean_sentence.split())):\n",
    "                \n",
    "                # convert word into lowercase\n",
    "                word=clean_sentence.split()[j].lower()\n",
    "\n",
    "                # if the word is a feature, we increase its count by 1\n",
    "                if word in features:\n",
    "                    index=np.where(features==word)\n",
    "                    vocabulary[i][index]+=1\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEXT CLASSIFICATION USING MULTINOMIAL NAIVE BAYES ALREADY IMPLEMENTED IN SKLERN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the 2d array with training data\n",
    "# by calling function get_2d_array\n",
    "\n",
    "x_train_2d_data=get_2d_array(x_train,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# create classifier object\n",
    "clf=MultinomialNB()\n",
    "\n",
    "# fitting the classifier using training data\n",
    "clf.fit(x_train_2d_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the 2d array with testing data\n",
    "x_test_2d_data=get_2d_array(x_test,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output using inbuilt predict function\n",
    "y_predict=clf.predict(x_test_2d_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       112\n",
      "           1       0.63      0.81      0.71       147\n",
      "           2       0.81      0.77      0.79       140\n",
      "           3       0.70      0.71      0.71       148\n",
      "           4       0.74      0.83      0.78       149\n",
      "           5       0.86      0.79      0.82       159\n",
      "           6       0.73      0.84      0.78       131\n",
      "           7       0.86      0.82      0.84       158\n",
      "           8       0.88      0.90      0.89       162\n",
      "           9       0.93      0.95      0.94       148\n",
      "          10       0.95      0.97      0.96       150\n",
      "          11       0.99      0.91      0.95       155\n",
      "          12       0.81      0.73      0.77       147\n",
      "          13       0.96      0.87      0.91       131\n",
      "          14       0.96      0.90      0.93       154\n",
      "          15       0.93      0.90      0.91       155\n",
      "          16       0.87      0.93      0.90       144\n",
      "          17       0.94      0.86      0.90       144\n",
      "          18       0.83      0.80      0.81       108\n",
      "          19       0.84      0.70      0.76        87\n",
      "\n",
      "    accuracy                           0.85      2829\n",
      "   macro avg       0.85      0.84      0.84      2829\n",
      "weighted avg       0.85      0.85      0.85      2829\n",
      "\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "[[100   0   0   0   0   0   0   0   1   0   0   0   0   1   0   4   0   2\n",
      "    2   2]\n",
      " [  1 119   6   4   1   5   4   0   1   0   0   0   4   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   4 108  15   1   7   4   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  12   8 105  13   1   5   0   0   0   0   0   3   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   6   0   9 123   0   6   1   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  22   7   2   1 125   0   0   1   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   5   4   1 110   2   1   0   3   0   1   0   1   0   1   1\n",
      "    0   0]\n",
      " [  0   1   0   0   5   0   7 130   7   1   0   0   3   0   0   0   2   0\n",
      "    0   2]\n",
      " [  0   0   0   2   0   0   2   7 146   1   0   0   1   1   1   0   1   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   3   0   0 140   2   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   3 145   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   3   0   0   0   4   0   0   0   0   0 141   2   0   0   0   2   0\n",
      "    2   0]\n",
      " [  0   5   4   7  14   0   1   5   1   0   1   0 107   0   1   0   1   0\n",
      "    0   0]\n",
      " [  0   3   1   0   1   2   3   1   0   0   0   0   0 114   2   2   2   0\n",
      "    0   0]\n",
      " [  1   7   0   0   0   0   0   0   1   3   1   0   3   0 138   0   0   0\n",
      "    0   0]\n",
      " [  4   1   0   0   2   0   2   0   1   0   0   0   1   0   0 139   0   2\n",
      "    1   2]\n",
      " [  0   0   0   0   0   0   2   2   0   1   0   0   0   0   0   0 134   0\n",
      "    4   1]\n",
      " [  2   1   0   0   2   0   0   0   1   0   0   0   1   0   0   1   2 124\n",
      "    6   4]\n",
      " [  6   1   0   0   0   0   1   1   2   2   0   1   0   0   0   0   4   3\n",
      "   86   1]\n",
      " [ 10   1   0   0   0   0   0   1   1   0   0   1   0   0   0   4   5   0\n",
      "    3  61]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the Classification report and \n",
    "# Confusion Matrix \n",
    "# using INBUILT Multinomial Naive Bayes \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('CLASSIFICATION REPORT')\n",
    "print()\n",
    "print(classification_report(y_test,y_predict))\n",
    "print()\n",
    "print('CONFUSION MATRIX')\n",
    "print()\n",
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After running the code for some different values of threshold,\n",
    "# I have plotted the graph\n",
    "# for Accuracy achieved vs No. of features taken\n",
    "# Accuracy increases as the words taken increased \n",
    "# but the time taken also increases.\n",
    "\n",
    "\n",
    "accuracy=[71,83,85,87]\n",
    "Number_of_features=[1000,3000,5000,10000]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Number_of_features,accuracy)\n",
    "plt.xlabel('Number of features selected from Vocabulary')\n",
    "plt.ylabel('Accuracy in %')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTING MULTINOMIAL NAIVE BAYES FROM SCRATCH ON MY OWN FOR TEXT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the fit function\n",
    "\n",
    "def fit(x_train,y_train):\n",
    "    \n",
    "    x_train=np.array(x_train)\n",
    "    y_train=np.array(y_train)\n",
    "    \n",
    "    result={}\n",
    "    \n",
    "    # unique values in the output\n",
    "    class_values=set(y_train)\n",
    "    \n",
    "    # iterating over each output of class\n",
    "    for current_class in class_values:\n",
    "        \n",
    "        result[current_class]={}\n",
    "        \n",
    "        result['total_data']=len(y_train)\n",
    "        \n",
    "        # rows of current class\n",
    "        bool_arr = (y_train==current_class)\n",
    "        \n",
    "        # training data for current class\n",
    "        x_train_current=x_train[bool_arr]\n",
    "        y_train_current=y_train[bool_arr]\n",
    "        \n",
    "        # storing the count of rows for which oytput is current class\n",
    "        result[current_class]['total_count']=len(y_train_current)\n",
    "        \n",
    "        total_words_current_class = 0\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            \n",
    "            # count of feature i in current_class\n",
    "            count=(x_train_current[:,i]).sum()\n",
    "            result[current_class][i] = count\n",
    "            \n",
    "            # finding the total count of words in the document i.e. in the current class\n",
    "            total_words_current_class += count\n",
    "        \n",
    "        # storing the total count of words in a given document in dictionary\n",
    "        result[current_class]['total_words'] = total_words_current_class\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary,x,current_class):\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # prior probability\n",
    "    output = np.log(dictionary[current_class]['total_count']) - np.log(dictionary['total_data'])\n",
    "    \n",
    "    for j in range(len(x)):\n",
    "        xj=x[j]\n",
    "        \n",
    "        # if a particular word doesn't exist in the document\n",
    "        # that is, its frequency is 0\n",
    "        # we simply don't consider the word in calculations\n",
    "        if xj>0:\n",
    "            \n",
    "            # Numerator\n",
    "            # Add 1 for Laplace Correction\n",
    "            nr = dictionary[current_class][j]+1\n",
    "            \n",
    "            # Denominator\n",
    "            # Add number of features for laplace correction\n",
    "            dr = dictionary[current_class]['total_words'] + len(features)\n",
    "            \n",
    "            # probability\n",
    "            p = nr/dr\n",
    "            \n",
    "            output += np.log(p)\n",
    "        \n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(dictionary,x):\n",
    "    \n",
    "    # output classes\n",
    "    classes=dictionary.keys()\n",
    "    \n",
    "    best_p=-1000\n",
    "    best_class=-1\n",
    "    first_run=True\n",
    "    \n",
    "    for current_class in classes:\n",
    "        if (current_class=='total_data'):\n",
    "            continue\n",
    "            \n",
    "        # probability that x belongs to this class\n",
    "        p_current_class = probability(dictionary,x,current_class)\n",
    "        \n",
    "        # finding the largest probability\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "        \n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary,x_test):\n",
    "    \n",
    "    # array for the predictions of the testing data\n",
    "    y_pred=[]\n",
    "    \n",
    "    # iterating over each point in the dataset to find the output class\n",
    "    for x in x_test:\n",
    "        x_class = predictSinglePoint(dictionary,x)\n",
    "        y_pred.append(x_class)\n",
    "    \n",
    "    # return the predicted output for testing data\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary= fit(x_train_2d_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_self = predict(dictionary,x_test_2d_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84       112\n",
      "           1       0.62      0.82      0.71       147\n",
      "           2       0.79      0.76      0.78       140\n",
      "           3       0.75      0.68      0.71       148\n",
      "           4       0.71      0.81      0.76       149\n",
      "           5       0.87      0.74      0.80       159\n",
      "           6       0.69      0.85      0.76       131\n",
      "           7       0.85      0.80      0.82       158\n",
      "           8       0.85      0.91      0.88       162\n",
      "           9       0.94      0.94      0.94       148\n",
      "          10       0.97      0.94      0.96       150\n",
      "          11       0.99      0.90      0.94       155\n",
      "          12       0.78      0.74      0.76       147\n",
      "          13       0.93      0.85      0.89       131\n",
      "          14       0.94      0.87      0.90       154\n",
      "          15       0.92      0.88      0.90       155\n",
      "          16       0.87      0.92      0.89       144\n",
      "          17       0.93      0.88      0.90       144\n",
      "          18       0.85      0.80      0.82       108\n",
      "          19       0.77      0.70      0.73        87\n",
      "\n",
      "    accuracy                           0.84      2829\n",
      "   macro avg       0.84      0.83      0.83      2829\n",
      "weighted avg       0.84      0.84      0.84      2829\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[ 99   0   0   0   0   0   0   0   1   0   0   0   0   1   0   4   0   2\n",
      "    2   3]\n",
      " [  0 120   8   3   2   4   4   0   2   0   0   0   2   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   6 107  12   2   5   3   1   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  13   7 100  17   0   7   0   0   0   0   0   3   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   7   2   8 121   0   5   2   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  25   8   2   1 118   1   0   0   0   0   0   1   0   2   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   2   5   1 111   1   1   0   1   1   2   1   2   0   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   5   0   9 126   5   0   0   0   7   0   1   0   3   0\n",
      "    0   2]\n",
      " [  0   0   0   2   0   0   4   5 148   1   0   0   0   0   1   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   4   0   1 139   2   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   1   1   2   4 141   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   3   0   0   0   5   0   0   0   0   0 140   1   0   0   0   4   0\n",
      "    1   0]\n",
      " [  0   4   3   4  14   1   2   5   2   0   1   0 109   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   5   1   0   1   1   3   3   1   0   0   0   1 111   2   2   0   0\n",
      "    0   0]\n",
      " [  1   6   0   0   0   0   0   1   4   2   0   0   3   1 134   1   0   0\n",
      "    1   0]\n",
      " [  2   1   0   0   2   0   2   0   2   0   0   0   0   2   0 136   0   2\n",
      "    0   6]\n",
      " [  1   0   0   0   0   0   2   2   0   1   0   0   1   0   0   0 132   0\n",
      "    3   2]\n",
      " [  3   1   0   0   1   0   1   0   2   0   0   0   1   0   0   1   2 126\n",
      "    4   2]\n",
      " [  5   0   0   0   0   0   2   1   3   1   0   1   0   0   0   0   3   3\n",
      "   86   3]\n",
      " [ 11   0   0   0   0   0   1   1   1   0   0   0   0   0   0   4   4   1\n",
      "    3  61]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the Classification report and \n",
    "# Confusion Matrix \n",
    "# using OUR OWN CODE OF Multinomial Naive Bayes \n",
    "\n",
    "print('CLASSIFICATION REPORT')\n",
    "print()\n",
    "print(classification_report(y_test,y_predict_self))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_test,y_predict_self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARISON\n",
    "## As can be seen, both ( inbuilt and self implemented Multinomial Naive Bayes ) are performing nearly the same.\n",
    "## One is doing good for few classes and other is doing good for some other output classes\n",
    "## Also, as we increase the number of features the results improve, but the time taken also increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For inbuilt Multinomial Naive Bayes Accuracy = 85 %\n",
    "## For own Multinomial Naive Bayes Accuracy = 84 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have taken no. of features = 5000\n",
    "## But did not wanted to increase further as the time being consumed was very large as compared to increase in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
